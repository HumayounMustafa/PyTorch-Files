{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwPWxctB1egg",
        "outputId": "999cd6c5-7d83-4a83-db80-de3f230b32de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1JcB8yJwKlH"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from einops import rearrange\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "class ShiftedWindowMSA(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads, window_size=7):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.proj1 = nn.Linear(embed_dim, 3*embed_dim)\n",
        "        self.proj2 = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_dim = self.embed_dim / self.num_heads\n",
        "        height = width = int(math.sqrt(x.shape[1])) #sqrt of 3969\n",
        "        x = self.proj1(x) #1,3969,288\n",
        "        x = rearrange(x, 'b (h w) (c K) -> b h w c K', K=3, h=height, w=width) #1,63,63,96,3\n",
        "        x = rearrange(x, 'b (h m1) (w m2) (H E) K -> b H h w (m1 m2) E K', H=self.num_heads, m1=self.window_size, m2=self.window_size)\n",
        "        #1,3,7,7,81,32,3\n",
        "\n",
        "        Q, K, V = x.chunk(3, dim=6)\n",
        "        print(Q.shape)\n",
        "        Q, K, V = Q.squeeze(-1), K.squeeze(-1), V.squeeze(-1)\n",
        "        print(Q.shape)\n",
        "        print(K.shape)\n",
        "        print(K.transpose(4,5).shape)\n",
        "        att_scores = (Q @ K.transpose(4,5)) / math.sqrt(h_dim)\n",
        "        print(att_scores.shape)\n",
        "        print(att_scores)\n",
        "        att = F.softmax(att_scores, dim=-1) @ V\n",
        "\n",
        "        x = rearrange(att, 'b H h w (m1 m2) E -> b (h m1) (w m2) (H E)', m1=self.window_size, m2=self.window_size)\n",
        "        x = rearrange(x, 'b h w c -> b (h w) c')\n",
        "\n",
        "        return self.proj2(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test=torch.randn(1,3969,96)\n",
        "obj=ShiftedWindowMSA(96,3)\n",
        "out=obj(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPpTCX831MKc",
        "outputId": "a1ee18da-aee5-4834-cf15-7a2fdc5b2e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 9, 9, 49, 32, 1])\n",
            "torch.Size([1, 3, 9, 9, 49, 32])\n",
            "torch.Size([1, 3, 9, 9, 49, 32])\n",
            "torch.Size([1, 3, 9, 9, 32, 49])\n",
            "torch.Size([1, 3, 9, 9, 49, 49])\n",
            "tensor([-0.0354,  0.4046, -0.2422, -0.0756,  0.3022,  0.3034,  0.0307,  0.1444,\n",
            "        -0.0678, -0.7405,  0.5652, -0.2716, -0.0853, -0.0629,  0.0171,  0.5844,\n",
            "         0.3814,  0.5636,  0.6189,  0.2669,  0.1224, -0.2086,  0.1773, -0.1738,\n",
            "        -0.0245,  0.0737, -0.0845,  0.2991,  0.4986, -0.0886, -0.0094,  0.0422,\n",
            "         0.0310, -0.4331, -0.1057,  0.2398,  0.3034,  0.2545,  0.1290, -0.2361,\n",
            "        -0.3241,  0.6415, -0.1865,  0.0423, -1.0829, -0.1173,  0.1321, -0.2014,\n",
            "         0.1646], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IenN2fEH2Bbm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}