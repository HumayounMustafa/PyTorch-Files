{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQWbRFSY4zyw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class CarvanaDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(image_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.image_dir, self.images[index])\n",
        "        mask_path = os.path.join(self.mask_dir, self.images[index].replace(\".jpg\", \"_mask.gif\"))\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n",
        "        mask[mask == 255.0] = 1.0\n",
        "\n",
        "        if self.transform is not None:\n",
        "            augmentations = self.transform(image=image, mask=mask)\n",
        "            image = augmentations[\"image\"]\n",
        "            mask = augmentations[\"mask\"]\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMm0VgJHYIAx",
        "outputId": "706d7a29-4862-4daf-c116-b5bc5003bdf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=CarvanaDataset(\"/content/train_images\",\"/content/train_masks\")"
      ],
      "metadata": {
        "id": "nTuk6Ky4-IKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "KO9T4_0F-izY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self,img_path,mask_path):\n",
        "    super().__init__()\n",
        "    self.img_path=img_path\n",
        "    self.mask_path=mask_path\n",
        "    self.images=os.listdir(img_path)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    image=os.path.join(self.img_path,self.images[index])\n",
        "    mask= os.path.join(self.mask_path, self.images[index].replace(\".jpg\", \"_mask.gif\"))\n",
        "\n",
        "    img=torch.from_numpy(np.array(Image.open(image).convert(\"RGB\")))\n",
        "    msk=torch.from_numpy(np.array(Image.open(mask).convert(\"L\")))\n",
        "\n",
        "    return img,msk\n",
        "\n"
      ],
      "metadata": {
        "id": "xBbGJ36B-lW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=MyDataset(\"/content/drive/MyDrive/UNETDataset/train_images\",\"/content/drive/MyDrive/UNETDataset/train_masks\")"
      ],
      "metadata": {
        "id": "9j41wHMgagSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader=torch.utils.data.DataLoader(dataset,batch_size=2,num_workers=2,shuffle=True)"
      ],
      "metadata": {
        "id": "0y2HYT-1a12w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  for batch_x, (data,mask) in enumerate(dataloader):\n",
        "    data=data.to(device=\"cuda\")\n",
        "    target-mask.to(device='cuda')\n",
        "\n",
        "    output=model(data)\n",
        "    loss=criterion(data,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "id": "rjAl3LFDa4hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Rn3pCbIQdH9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "XSMbbFuCdJiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self,img_path,msk_path):\n",
        "    super().__init__()\n",
        "    self.image_path=img_path\n",
        "    self.mask_path=msk_path\n",
        "    self.images=os.listdir(self.image_path)\n",
        "    self.preprocess=transforms.Compose(transforms.Resize(140),\n",
        "                                       transforms.HorizontalFlip(),\n",
        "                                       transforms.CenterCrop(),transforms.ToTensor())\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "  def __getitem__(self,index):\n",
        "    img=os.path.join(self.image_path,self.images[index])\n",
        "    mask=os.path.join(self.mask_path,self.images[index].replace(\".jpg\",\"._mask.gif\"))\n",
        "\n",
        "    image=Image.open(img).convert(\"RGB\")),dtype=torch.float32)\n",
        "    mask=Image.open(mask).convert(\"L\")),dtype=torch.float32)\n",
        "\n",
        "    img=self.preprocess(image)\n",
        "    mask=self.preprocess(mask)\n",
        "\n",
        "    return image,mask\n",
        "\n"
      ],
      "metadata": {
        "id": "ze1H7fQddKdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=MyDataset(\"/content/drive/MyDrive/UNETDataset/train_images\",\"/content/drive/MyDrive/UNETDataset/train_masks\")"
      ],
      "metadata": {
        "id": "CNGbxPnMpL7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader=torch.utils.data.DataLoader(dataset,batch_size=2,num_workers=2,shuffle=True)"
      ],
      "metadata": {
        "id": "8F9iHyHTpXG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=5\n",
        "for i in range(epochs):\n",
        "  for batch,data in enumerate(dataloader):\n",
        "    imgs=data[0].to(device='cuda')\n",
        "    masks=data[1].to(device='cuda')\n",
        "\n",
        "    outputs=model(img)\n",
        "    loss=criterion(outputs,mask)\n",
        "    loss.backward\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "a7M104plpfbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self,img_path,msk_path):\n",
        "    super().__init__()\n",
        "    self.image_path=img_path\n",
        "    self.mask_path=msk_path\n",
        "    self.images=os.listdir(self.image_path)\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "  def __getitem__(self,index):\n",
        "    img=os.path.join(self.image_path,self.images[index])\n",
        "    mask=os.path.join(self.mask_path,self.images[index].replace(\".jpg\",\"_mask.gif\"))\n",
        "\n",
        "    image=torch.from_numpy(np.array(Image.open(img).convert(\"RGB\")),dtype=torch.float32)\n",
        "    mask1=torch.from_numpy(np.array(Image.open(mask).convert(\"L\")),dtype=torch.float32)\n",
        "\n",
        "    return image,mask1\n",
        "\n"
      ],
      "metadata": {
        "id": "yTwGqzrw4wqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=MyDataset(\"/content/drive/MyDrive/UNETDataset/train_images\",\"/content/drive/MyDrive/UNETDataset/train_masks\")"
      ],
      "metadata": {
        "id": "y8pfdlXOAemH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader=torch.utils.data.DataLoader(dataset,batch_size=2,num_workers=2,shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0c5Wr6yAryU",
        "outputId": "89fa1d2e-eef6-4e29-ac3b-42d4da6e99d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=5\n",
        "for i in range(epochs):\n",
        "  for batch,(data,mask) in enumerate(dataloader):\n",
        "    data=data.to(device='cuda')\n",
        "    mask=mask.to(device='cuda')\n",
        "\n",
        "    output=model(data)\n",
        "    loss=criterion(output,mask)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "pDGmt8iKAuF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=[5,6,7,8,9]\n",
        "\n",
        "for index,value in enumerate(a):\n",
        "  print(index, value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPikoxM6ETn4",
        "outputId": "b72a134d-4715-4ff0-d84e-d76e50a7549c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 5\n",
            "1 6\n",
            "2 7\n",
            "3 8\n",
            "4 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8P9m_d7Eb0H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}